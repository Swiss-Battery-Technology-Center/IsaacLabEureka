**Summary of SBTC Unscrew Environment Configuration**

**Reward Components:**
1. **EE Verticality (Axis Alignment):**
   - *Computation:* Measures alignment between end-effector's vertical axis and target orientation (Y-axis up). Uses vector similarity between current EE orientation and target quaternion.
   - *Purpose:* Ensures proper screwdriver alignment for engagement. Provides continuous reward based on cosine similarity (range: 0-1 before scaling).

2. **Yaw Alignment:**
   - *Computation:* Compares yaw angle difference between object and EE using 6x symmetry (for hexagonal screws). Calculated via angular difference in 60° increments.
   - *Purpose:* Aligns screwdriver with screw head's rotation axis. Provides dense reward for rotational alignment.

3. **Position Similarity (Coarse/Medium/Fine):**
   - *Computation:* Three-tiered proximity rewards using exponential decay functions (σ=5,50,100) to create concentric reward fields around target position. Coarse (0.25x) rewards proximity up to 20cm, Medium (0.5x) up to 2cm, Fine (0.75x) up to 1cm.
   - *Purpose:* Creates dense reward gradients at different spatial scales to guide EE toward target.

4. **Screw Engagement:**
   - *Computation:* Binary reward (0/1) using tanh step function. Activates when EE is within 0.2mm of target (σ=0.0007). Combines with position similarity rewards.
   - *Purpose:* Final engagement reward for successful contact. Threshold set slightly above surface to encourage contact force.

5. **Contact Management:**
   - *Screw Contact:* Rewards contact forces >2.5N in Z-axis (screw axis)
   - *Table Contact:* Penalizes contact with table (body ID 1) with -10x penalty
   - *Purpose:* Teaches controlled contact with screw while avoiding collisions.

6. **Motion Regularization:**
   - *Action Rate:* L2 penalty on action changes (Δa) to encourage smooth control
   - *Joint Velocity:* Penalizes high joint velocities (L2 norm) for safety

**Curriculum Components:**
1. **Position Similarity Offset Reduction:**
   - *Parameters:* Reduces Z-offset in position rewards from 0.006m to 0m over 300-600k steps
   - *Effect:* Gradually moves "sweet spot" closer to actual contact point as policy improves

2. **Joint Effort Deadzone Expansion:**
   - *Parameters:* Increases deadzone from 0.1N to 0.5N over 1.1M steps
   - *Effect:* Allows larger control inputs as policy becomes more precise

3. **EE Pose Randomization:**
   - *Parameters:* Reduces position noise from 4cm to 2cm and orientation noise from 0.2 rad to 0.2 rad over 600k steps
   - *Effect:* Starts with large initial randomization for exploration, then tightens as policy converges

**Domain Randomization:**
1. **Initial Pose Randomization:**
   - Object position: ±10cm XYZ, ±60° yaw
   - EE position: ±4cm XYZ, ±0.2 rad orientation

2. **Dynamic Randomization:**
   - PD gains randomized (50-150 P, 0.25-1.75 D)
   - Joint effort deadzone randomized (0-0.1N)

**Key Environment Structure:**
- 100Hz physics (10ms timestep) with 4:1 control decimation
- 1024 parallel environments with 2.5m spacing
- Contact detection uses filtered primitives (screw vs table)
- Observation space includes EE position (3), rotation (3), velocity (6), actions (6), object position (3), yaw (1), contact forces (3)

**Reward Synergy:**
The coarse position rewards create broad exploration, medium rewards guide to proximity, and fine rewards enable precise alignment. Verticality/yaw rewards ensure proper orientation while contact rewards and penalties shape the interaction. The curriculum's offset reduction coordinates with position rewards to progressively focus on precise engagement.

**Curriculum Impact:**
Initial large position offsets and randomization allow exploration of the workspace. As the policy improves, the system reduces position tolerances and increases control precision requirements while maintaining safety through velocity penalties. The deadzone expansion allows more aggressive control once the policy can reliably approach the target.